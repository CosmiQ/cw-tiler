{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook demonstrates the tool for Searching GBDX and ordering Imagery\n",
    "This script was used for acquisition of Atlanta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gbdxtools import Interface\n",
    "gbdx = Interface()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Search Area for Atlanta\n",
    "area_of_interest = \"POLYGON((-84.44512435851775933 33.78293430345136983, -84.34661228447379244 33.78312166782949078, -84.33917315760092492 33.67325591918615402, -84.44782949556243068 33.67044181031717187, -84.44512435851775933 33.78293430345136983))\"\n",
    "start_date=\"2009-12-22T00:00:00.000Z\"\n",
    "end_date=\"2009-12-23T00:00:00.000Z\"\n",
    "results = gbdx.catalog.search(searchAreaWkt=area_of_interest, \n",
    "                              startDate=start_date, endDate=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# create dataframe from search results\n",
    "catalog_df = pd.DataFrame([r['properties'] for r in results])\n",
    "imagePrefix = \"AOI_6_Atlanta/Atlanta_nadir{}_catid_{}\"\n",
    "catalog_df=catalog_df[catalog_df['platformName']=='WORLDVIEW02']\n",
    "timeZ = catalog_df['timestamp'].sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save AOI Details to CSV.  \n",
    "catalog_df[['catalogID','timestamp', 'panResolution','offNadirAngle', 'targetAzimuth']].sort_values(by=['timestamp']).reset_index().drop('index',axis=1).to_csv(\"AOI_Collect_Details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderList = []\n",
    "workflowList = []\n",
    "orderDictList = []\n",
    "\n",
    "for idx, row in catalog_df.iterrows():\n",
    "    \n",
    "    # Use data from Catalog to create imagePrefix for saving\n",
    "    catid = row['catalogID']\n",
    "    output_location = imagePrefix.format(int(row['offNadirAngle']), catid)\n",
    "    \n",
    "    \n",
    "    # Use gbdx ordering \n",
    "    order = gbdx.Task('Auto_Ordering')\n",
    "    order.inputs.cat_id = catid\n",
    "    order.impersonation_allowed=True\n",
    "    \n",
    "    # send GBDX Order\n",
    "    orderDict = {'orderLocation': order.outputs.s3_location,\n",
    "                'pan_ms_location': output_location,\n",
    "                'catid': catid}\n",
    "    \n",
    "    order.outputs.s3_location\n",
    "    \n",
    "    ## Sent gbdx task\n",
    "    aoptask = gbdx.Task('AOP_Strip_Processor', \n",
    "                        data=order.outputs.s3_location, \n",
    "                        enable_dra=False, \n",
    "                        ortho_epsg='UTM',\n",
    "                       enable_pansharpen=False,\n",
    "                       enable_acomp=True)\n",
    " \n",
    "    workflow = gbdx.Workflow([order,aoptask])\n",
    "    \n",
    "    ## Save data\n",
    "    workflow.savedata(aoptask.outputs.data, location=output_location)\n",
    "    workflow.execute()\n",
    "    \n",
    "    # Store Order and Workflow to check status\n",
    "    orderList.append(order)\n",
    "    workflowList.append(workflow)\n",
    "    \n",
    "    orderDictList.append(orderDict)\n",
    "\n",
    "import json\n",
    "## Write order results for further query\n",
    "with open('/raid/nfs/data/Datasets/CosmiQ_General_Study/AOI_6_Atlanta/order.json', 'w') as fout:\n",
    "    json.dump(orderDictList, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print workflow status\n",
    "for workflow in workflowList:\n",
    "    print(workflow.status)\n",
    "#for order_id in orderList:\n",
    "#    gbdx.ordering.status(print(order_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cw_environment]",
   "language": "python",
   "name": "conda-env-cw_environment-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
